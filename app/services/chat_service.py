from typing import Dict, Any, List
import uuid
import re
import logging
import json
from pathlib import Path
from rapidfuzz import fuzz
from app.repositories.chat_repository import chat_repository
from app.repositories.ranking_repository import ranking_repository
from app.services.openai_service import openai_service
from app.services.knowledge_service import knowledge_service
from app.core.config import settings
from app.services.ranking_service import ranking_service
from app.schemas.ranking import RankingSearchRequest
import datetime
from app.services.university_service import university_service
import unicodedata

logger = logging.getLogger("chat_service")

class ChatService:
    def __init__(self):
        # Load knowledge_base keywords (greeting, school, major, ...)
        kb_path = Path(__file__).parent.parent / "data" / "knowledge_base.json"
        with open(kb_path, "r", encoding="utf-8") as f:
            self.knowledge_base = json.load(f)
        self.greeting_keywords = self.knowledge_base.get("greeting", {}).get("keywords", [])
        self.school_keywords = self.knowledge_base.get("school_recommendation", {}).get("keywords", [])
        self.major_keywords = self.knowledge_base.get("major_advice", {}).get("keywords", [])
        # Build intent_keywords mapping from all keys in knowledge_base.json that c√≥ 'keywords'
        self.intent_keywords = {k: v["keywords"] for k, v in self.knowledge_base.items() if isinstance(v, dict) and "keywords" in v}

    async def create_session(self) -> str:
        # N·∫øu c·∫ßn user_id, c√≥ th·ªÉ sinh ng·∫´u nhi√™n ho·∫∑c b·ªè qua
        user_id = "anonymous"
        return await chat_repository.create_session(user_id)

    def detect_intent(self, message: str) -> str:
        message_lower = message.lower()
        # Priority 0: Detect greeting messages
        if any(greeting in message_lower for greeting in self.greeting_keywords) and len(message.split()) <= 5:
            return "greeting"
        # Priority 1: Detect s·ªë b√°o danh (8 ch·ªØ s·ªë)
        sbd_pattern = r'\b\d{8}\b'
        if re.search(sbd_pattern, message):
            return "score_lookup"
        # Priority 2: Detect t√™n tr∆∞·ªùng c·ª• th·ªÉ
        if any(school in message_lower for school in self.school_keywords):
            return "school_recommendation"
        # Priority 3: Detect ng√†nh h·ªçc c·ª• th·ªÉ
        if any(major in message_lower for major in self.major_keywords):
            return "major_advice"
        # Priority 4: Fuzzy match t·ª´ng intent theo ƒë√∫ng keywords trong knowledge_base.json
        intent_scores = {}
        for category, keywords in self.intent_keywords.items():
            score = 0
            for keyword in keywords:
                if fuzz.partial_ratio(keyword, message_lower) >= 80:
                    score += 1
            if score > 0:
                intent_scores[category] = score
        if intent_scores:
            sorted_intents = sorted(intent_scores.items(), key=lambda x: (-x[1], list(self.intent_keywords.keys()).index(x[0])))
            return sorted_intents[0][0]
        return "general"
    
    def extract_candidate_number(self, message: str) -> str:
        """Tr√≠ch xu·∫•t s·ªë b√°o danh t·ª´ tin nh·∫Øn"""
        sbd_pattern = r'\b(\d{8})\b'
        match = re.search(sbd_pattern, message)
        return match.group(1) if match else None

    def extract_entities(self, message: str) -> Dict[str, Any]:
        """Tr√≠ch xu·∫•t c√°c th·ª±c th·ªÉ t·ª´ tin nh·∫Øn"""
        entities = {
            'candidate_number': self.extract_candidate_number(message),
            'school_name': knowledge_service._extract_school_name(message),
            'major_name': knowledge_service._extract_major_name(message),
            'location': self._extract_location(message)
        }
        return {k: v for k, v in entities.items() if v}

    def _extract_location(self, message: str) -> str:
        """Tr√≠ch xu·∫•t t√™n ƒë·ªãa ƒëi·ªÉm"""
        locations = [
            "h√† n·ªôi", "tp.hcm", "s√†i g√≤n", "ƒë√† n·∫µng", "c·∫ßn th∆°",
            "h·∫£i ph√≤ng", "hu·∫ø", "nha trang", "mi·ªÅn b·∫Øc", "mi·ªÅn nam", "mi·ªÅn trung"
        ]
        message_lower = message.lower()
        for location in locations:
            if location in message_lower:
                return location
        return None

    async def get_student_data_if_available(self, message: str) -> Dict[str, Any]:
        """L·∫•y th√¥ng tin ƒëi·ªÉm thi n·∫øu c√≥ SBD trong tin nh·∫Øn"""
        candidate_number = self.extract_candidate_number(message)
        if candidate_number:
            try:
                student_data = await ranking_repository.get_by_candidate_number(candidate_number)
                return student_data
            except Exception as e:
                logger.error(f"Error getting student data: {e}")
                return {"error": "Kh√¥ng t√¨m th·∫•y th√¥ng tin ƒëi·ªÉm thi cho SBD n√†y"}
        return None

    def analyze_specific_question(self, message: str) -> Dict[str, Any]:
        """Ph√¢n t√≠ch c√¢u h·ªèi c·ª• th·ªÉ ƒë·ªÉ ƒë∆∞a ra c√¢u tr·∫£ l·ªùi focused"""
        message_norm = self.normalize_text(message)
        
        # Mapping c√°c c√¢u h·ªèi c·ª• th·ªÉ
        specific_questions = {
            "established": {
                "keywords": ["nƒÉm th√†nh l·∫≠p", "th√†nh l·∫≠p", "th√†nh l·∫≠p nƒÉm", "ƒë∆∞·ª£c th√†nh l·∫≠p", "creation", "founded"],
                "response_format": "short"
            },
            "tuition": {
                "keywords": ["h·ªçc ph√≠", "ph√≠ h·ªçc", "chi ph√≠", "gi√° h·ªçc", "tuition", "cost"],
                "response_format": "short"
            },
            "admission_score": {
                "keywords": ["ƒëi·ªÉm chu·∫©n", "ƒëi·ªÉm ƒë·∫ßu v√†o", "ƒëi·ªÉm tuy·ªÉn sinh", "admission score"],
                "response_format": "medium"
            },
            "location": {
                "keywords": ["·ªü ƒë√¢u", "ƒë·ªãa ch·ªâ", "t·ªça l·∫°c", "v·ªã tr√≠", "location"],
                "response_format": "short"
            },
            "ranking": {
                "keywords": ["ranking", "x·∫øp h·∫°ng", "uy t√≠n", "ch·∫•t l∆∞·ª£ng"],
                "response_format": "short"
            },
            "student_count": {
                "keywords": ["bao nhi√™u sinh vi√™n", "s·ªë sinh vi√™n", "quy m√¥"],
                "response_format": "short"
            },
            "employment_rate": {
                "keywords": ["t·ª∑ l·ªá vi·ªác l√†m", "vi·ªác l√†m", "ra tr∆∞·ªùng", "employment"],
                "response_format": "short"
            }
        }
        
        for question_type, config in specific_questions.items():
            if any(keyword in message_norm for keyword in config["keywords"]):
                return {
                    "type": question_type,
                    "format": config["response_format"]
                }
        
        return {"type": "general", "format": "full"}

    def generate_focused_response(self, school_doc: Dict, question_analysis: Dict, school_name: str) -> str:
        """T·∫°o c√¢u tr·∫£ l·ªùi focused d·ª±a tr√™n c√¢u h·ªèi c·ª• th·ªÉ"""
        question_type = question_analysis["type"]
        
        if question_type == "established":
            if "established" in school_doc:
                return f"**{school_name}** ƒë∆∞·ª£c th√†nh l·∫≠p nƒÉm **{school_doc['established']}**."
            return f"Th√¥ng tin nƒÉm th√†nh l·∫≠p c·ªßa {school_name} ch∆∞a ƒë∆∞·ª£c c·∫≠p nh·∫≠t trong h·ªá th·ªëng."
        
        elif question_type == "tuition":
            if "hoc_phi" in school_doc and school_doc["hoc_phi"]:
                hoc_phi = school_doc["hoc_phi"]
                if isinstance(hoc_phi, dict):
                    response = f"**H·ªçc ph√≠ {school_name}:**\n"
                    if "khung_gia" in hoc_phi:
                        response += f"- Khung gi√°: {hoc_phi['khung_gia']}\n"
                    if "chi_tiet" in hoc_phi:
                        response += f"- Chi ti·∫øt: {hoc_phi['chi_tiet']}"
                    return response
                return f"**H·ªçc ph√≠ {school_name}:** {hoc_phi}"
            return f"Th√¥ng tin h·ªçc ph√≠ c·ªßa {school_name} ch∆∞a ƒë∆∞·ª£c c·∫≠p nh·∫≠t trong h·ªá th·ªëng."
        
        elif question_type == "admission_score":
            if "diem_chuan" in school_doc and school_doc["diem_chuan"]:
                diem_chuan = school_doc["diem_chuan"]
                response = f"**ƒêi·ªÉm chu·∫©n {school_name}:**\n"
                for year, year_data in diem_chuan.items():
                    response += f"**NƒÉm {year}:**\n"
                    if isinstance(year_data, dict):
                        if "cao_nhat" in year_data:
                            response += f"- Cao nh·∫•t: {year_data['cao_nhat']}\n"
                        if "thap_nhat" in year_data:
                            response += f"- Th·∫•p nh·∫•t: {year_data['thap_nhat']}\n"
                return response.rstrip()
            return f"Th√¥ng tin ƒëi·ªÉm chu·∫©n c·ªßa {school_name} ch∆∞a ƒë∆∞·ª£c c·∫≠p nh·∫≠t trong h·ªá th·ªëng."
        
        elif question_type == "location":
            if "location" in school_doc:
                return f"**{school_name}** t·ªça l·∫°c t·∫°i **{school_doc['location']}**."
            return f"Th√¥ng tin ƒë·ªãa ƒëi·ªÉm c·ªßa {school_name} ch∆∞a ƒë∆∞·ª£c c·∫≠p nh·∫≠t trong h·ªá th·ªëng."
        
        elif question_type == "ranking":
            if "ranking" in school_doc:
                return f"**X·∫øp h·∫°ng {school_name}:** {school_doc['ranking']}"
            return f"Th√¥ng tin x·∫øp h·∫°ng c·ªßa {school_name} ch∆∞a ƒë∆∞·ª£c c·∫≠p nh·∫≠t trong h·ªá th·ªëng."
        
        elif question_type == "student_count":
            if "so_sinh_vien" in school_doc:
                return f"**{school_name}** hi·ªán c√≥ **{school_doc['so_sinh_vien']}** sinh vi√™n."
            return f"Th√¥ng tin s·ªë l∆∞·ª£ng sinh vi√™n c·ªßa {school_name} ch∆∞a ƒë∆∞·ª£c c·∫≠p nh·∫≠t trong h·ªá th·ªëng."
        
        elif question_type == "employment_rate":
            if "ty_le_viec_lam" in school_doc:
                return f"**T·ª∑ l·ªá vi·ªác l√†m sau t·ªët nghi·ªáp c·ªßa {school_name}:** {school_doc['ty_le_viec_lam']}"
            return f"Th√¥ng tin t·ª∑ l·ªá vi·ªác l√†m c·ªßa {school_name} ch∆∞a ƒë∆∞·ª£c c·∫≠p nh·∫≠t trong h·ªá th·ªëng."
        
        # Fallback to full info n·∫øu kh√¥ng match specific question
        return None

    async def process_message_stream(self, session_id: str, user_message: str):
        try:
            # 1. Ph√°t hi·ªán √Ω ƒë·ªãnh v√† entities
            intent = self.detect_intent(user_message)
            entities = self.extract_entities(user_message)
            
            # 2. L·∫•y l·ªãch s·ª≠ chat
            chat_history = await chat_repository.get_chat_history(session_id, limit=settings.chat_history_limit)
            
            # Build context an to√†n
            context = []
            for msg in chat_history:
                if msg.get("user_message"):
                    context.append({"role": "user", "content": msg["user_message"]})
                if msg.get("bot_response"):
                    context.append({"role": "assistant", "content": msg["bot_response"]})
            # L·ªçc l·∫°i context cho ch·∫Øc ch·∫Øn
            context = [m for m in context if m.get("role") and m.get("content")]
            
            # 3. L·∫•y th√¥ng tin ƒëi·ªÉm thi n·∫øu c√≥ SBD
            student_data = await self.get_student_data_if_available(user_message)

            # 3.1. Tr√≠ch xu·∫•t t√™n n·∫øu user gi·ªõi thi·ªáu b·∫£n th√¢n
            name = None
            name_patterns = [
                r"t√¥i t√™n ([A-Za-z√Ä-·ªπ√†-·ªπ'\- ]{2,50})",
                r"m√¨nh t√™n ([A-Za-z√Ä-·ªπ√†-·ªπ'\- ]{2,50})",
                r"t√™n t√¥i l√† ([A-Za-z√Ä-·ªπ√†-·ªπ'\- ]{2,50})",
                r"my name is ([A-Za-z√Ä-·ªπ√†-·ªπ'\- ]{2,50})",
            ]
            blacklist = {"g√¨", "g√¨?", "g√¨.", "ai", "b·∫°n", "m√¨nh", "t√¥i", "t√™n", "l√†", "v·∫≠y", "kh√¥ng", "?", ".", ""}
            for pattern in name_patterns:
                match = re.search(pattern, user_message, re.IGNORECASE)
                if match:
                    raw_name = match.group(1).strip()
                    cleaned_name = ' '.join(raw_name.split())
                    cleaned_name = cleaned_name.title()
                    if cleaned_name.split()[0].lower() not in blacklist:
                        name = cleaned_name
                    break

            # 4. X·ª≠ l√Ω ƒë·∫∑c bi·ªát cho score_lookup
            if intent == "score_lookup":
                candidate_number = entities.get('candidate_number')
                # Parse year t·ª´ message, m·∫∑c ƒë·ªãnh 2025
                year = 2025
                year_match = re.search(r"\b(20\d{2})\b", user_message)
                if year_match:
                    year = int(year_match.group(1))
                current_year = datetime.datetime.now().year
                
                # L·∫•y categories t·ª´ knowledge_base.json
                kb_categories = []
                try:
                    kb_categories = knowledge_service.kb_json.get("score_lookup", {}).get("categories", [])
                except Exception:
                    kb_categories = []
                if not kb_categories:
                    kb_categories = ["thptqg"]
                
                category_found = False
                for cat in kb_categories:
                    if cat.lower() in user_message.lower():
                        category_found = True
                        break
                
                # N·∫øu kh√¥ng c√≥ keyword k·ª≥ thi n√†o, m·∫∑c ƒë·ªãnh l√† THPTQG v√† year=2025
                if not category_found and not year_match:
                    category_found = True
                    year = 2025
                
                if not category_found:
                    bot_response = (
                        "Hi·ªán t·∫°i h·ªá th·ªëng ch·ªâ h·ªó tr·ª£ tra c·ª©u ƒëi·ªÉm thi THPTQG. "
                        "C√°c k·ª≥ thi kh√°c (ƒêGNL, ...), vui l√≤ng th·ª≠ l·∫°i sau khi c√≥ d·ªØ li·ªáu ho·∫∑c li√™n h·ªá ƒë∆°n v·ªã t·ªï ch·ª©c k·ª≥ thi ƒë√≥ ƒë·ªÉ bi·∫øt th√™m th√¥ng tin."
                    )
                elif year < 2025:
                    bot_response = "H·ªá th·ªëng hi·ªán t·∫°i ch·ªâ c√≥ data s·ªë b√°o danh c·ªßa 2025, c√°c nƒÉm v·ªÅ tr∆∞·ªõc xin vui l√≤ng th·ª≠ l·∫°i sau."
                elif year > current_year or year > 2025:
                    bot_response = (
                        f"B·∫°n v·ª´a h·ªèi tra c·ª©u ƒëi·ªÉm thi nƒÉm {year}. "
                        "Hi·ªán t·∫°i h·ªá th·ªëng EduPath ch·ªâ h·ªó tr·ª£ d·ªØ li·ªáu ƒëi·ªÉm thi v√† x·∫øp h·∫°ng cho k·ª≥ thi THPT Qu·ªëc gia nƒÉm 2025. "
                        "C√°c nƒÉm sau s·∫Ω ƒë∆∞·ª£c c·∫≠p nh·∫≠t khi c√≥ d·ªØ li·ªáu ch√≠nh th·ª©c t·ª´ B·ªô Gi√°o d·ª•c v√† ƒê√†o t·∫°o. "
                        "Vui l√≤ng quay l·∫°i sau khi k·ª≥ thi nƒÉm ƒë√≥ k·∫øt th√∫c ho·∫∑c li√™n h·ªá v·ªõi nh√† tr∆∞·ªùng/ƒë∆°n v·ªã t·ªï ch·ª©c ƒë·ªÉ bi·∫øt th√™m th√¥ng tin m·ªõi nh·∫•t."
                    )
                else:
                    if not candidate_number:
                        bot_response = (
                            "ƒê·ªÉ tra c·ª©u b·∫£ng x·∫øp h·∫°ng THPT Qu·ªëc Gia, b·∫°n vui l√≤ng cung c·∫•p:\n"
                            "- S·ªë b√°o danh (8 ch·ªØ s·ªë)\n"
                            "- Khu v·ª±c thi (CN, MB, MT, MN)\n"
                            "V√≠ d·ª•: 'SBD: 12345678, Khu v·ª±c: MB'"
                        )
                    else:
                        # Parse region t·ª´ message, m·∫∑c ƒë·ªãnh CN
                        region = "CN"
                        for reg in ["CN", "MB", "MT", "MN"]:
                            if reg.lower() in user_message.lower():
                                region = reg
                                break
                        
                        req = RankingSearchRequest(candidate_number=candidate_number, region=region)
                        student_obj = await ranking_service.get_student_ranking(req, save_to_db=True)
                        
                        if not student_obj:
                            bot_response = f"Kh√¥ng t√¨m th·∫•y th√¥ng tin cho SBD {candidate_number} ho·∫∑c s·ªë b√°o danh kh√¥ng t·ªìn t·∫°i."
                        else:
                            # Ph√¢n t√≠ch user h·ªèi ƒëi·ªÉm, ranking, hay c·∫£ hai
                            ask_score = any(k in user_message.lower() for k in ["ƒëi·ªÉm", "score"])
                            ask_rank = any(k in user_message.lower() for k in ["ranking", "x·∫øp h·∫°ng", "rank"])
                            
                            msg_parts = []
                            if ask_score or not (ask_score or ask_rank):
                                mark_info = getattr(student_obj, "mark_info", [])
                                if mark_info:
                                    msg_parts.append("**K·∫øt qu·∫£ ƒëi·ªÉm c√°c m√¥n:**")
                                    for m in mark_info:
                                        msg_parts.append(f"- {m.name}: {m.score}")
                            
                            if ask_rank or not (ask_score or ask_rank):
                                blocks = getattr(student_obj, "blocks", [])
                                if blocks:
                                    msg_parts.append("\n**X·∫øp h·∫°ng theo kh·ªëi v√† khu v·ª±c:**")
                                    for block in blocks:
                                        label = getattr(block, "label", "")
                                        point = getattr(block, "point", "")
                                        region = getattr(block, "region", "")
                                        year = getattr(block, "year", 2025)
                                        ranking = getattr(block, "ranking", None)
                                        rank_str = f"- {label} ({region}, {year}): {point} ƒëi·ªÉm"
                                        if ranking:
                                            higher = getattr(ranking, "higher", 0)
                                            total = getattr(ranking, "total", 1)
                                            rank_str += f" | X·∫øp h·∫°ng: top {round((1-(higher/total))*100,2)}% ({higher}/{total})"
                                        msg_parts.append(rank_str)
                            
                            bot_response = "\n".join(msg_parts) if msg_parts else "Kh√¥ng c√≥ d·ªØ li·ªáu ƒëi·ªÉm ho·∫∑c ranking cho SBD n√†y."
                
                # L∆∞u v√†o history v√† chunk t·ª´ng ph·∫ßn
                chat_message = await chat_repository.create_message(
                    session_id, user_message, bot_response, intent
                )
                
                import asyncio
                await asyncio.sleep(3)  # Delay 3s cho FE hi·ªÉn th·ªã tr·∫°ng th√°i 'ƒëang suy nghƒ©'
                
                # ‚úÖ FIX: Chunk text properly
                for chunk in self.chunk_text(bot_response):
                    yield chunk
                return
            
            # 5. X·ª≠ l√Ω c√°c intent kh√°c
            else:
                # Ki·ªÉm tra n·∫øu l√† c√¢u h·ªèi v·ªÅ tr∆∞·ªùng c·ª• th·ªÉ
                if intent in ["school_recommendation", "admission_score", "major_advice"]:
                    # Chu·∫©n h√≥a t√™n tr∆∞·ªùng t·ª´ user_message
                    school_name = None
                    universities = await university_service.get_all_universities_from_db()
                    user_text_norm = self.normalize_text(user_message)
                    school_doc = None
                    for uni in universities:
                        # So s√°nh code, alias, name, kh√¥ng d·∫•u
                        if (
                            ("code" in uni and uni["code"].lower() in user_text_norm) or
                            ("alias" in uni and self.normalize_text(uni["alias"]) in user_text_norm) or
                            ("name" in uni and self.normalize_text(uni["name"]) in user_text_norm)
                        ):
                            school_name = uni["name"]
                            school_doc = uni
                            break
                    # N·∫øu t√¨m ƒë∆∞·ª£c tr∆∞·ªùng trong DB
                    if school_name and school_doc:
                        # ∆Øu ti√™n extract field c·ª• th·ªÉ t·ª´ c√¢u h·ªèi
                        field_key = self.extract_university_info_from_question(user_message)
                        if field_key and field_key in school_doc:
                            # Ch·ªâ tr·∫£ v·ªÅ field n√†y
                            field_labels = self.get_university_field_labels()
                            value = school_doc[field_key]
                            if field_key == "diem_chuan":
                                # Format ri√™ng cho ƒëi·ªÉm chu·∫©n
                                diem_chuan = value
                                lines = [f"**{school_name}**\n", f"**{field_labels.get('diem_chuan', 'ƒêi·ªÉm chu·∫©n')}:**"]
                                for year, year_data in diem_chuan.items():
                                    lines.append(f"- **NƒÉm {year}:**")
                                    if isinstance(year_data, dict):
                                        if "cao_nhat" in year_data:
                                            lines.append(f"  - Cao nh·∫•t: {year_data['cao_nhat']}")
                                        if "thap_nhat" in year_data:
                                            lines.append(f"  - Th·∫•p nh·∫•t: {year_data['thap_nhat']}")
                                        if "nganh_hot" in year_data and isinstance(year_data["nganh_hot"], list):
                                            lines.append(f"  - Ng√†nh hot:")
                                            for ng in year_data["nganh_hot"]:
                                                lines.append(f"    - {ng.get('nganh', '')}: {ng.get('diem', '')}")
                                response = "\n".join(lines)
                            elif field_key == "hoc_phi" and isinstance(value, dict):
                                lines = [f"**{school_name}**\n", f"**{field_labels.get('hoc_phi', 'H·ªçc ph√≠')}:**"]
                                if "khung_gia" in value:
                                    lines.append(f"- Khung gi√°: {value['khung_gia']}")
                                if "chi_tiet" in value:
                                    lines.append(f"- Chi ti·∫øt: {value['chi_tiet']}")
                                response = "\n".join(lines)
                            elif field_key in ["hoc_bong", "dac_sac"] and isinstance(value, list):
                                lines = [f"**{school_name}**\n", f"**{field_labels.get(field_key, field_key)}:**"]
                                for v in value:
                                    lines.append(f"- {v}")
                                response = "\n".join(lines)
                            else:
                                response = f"**{school_name}**\n- **{field_labels.get(field_key, field_key)}:** {value}"
                            chat_message = await chat_repository.create_message(
                                session_id, user_message, response, intent
                            )
                            import asyncio
                            await asyncio.sleep(3)
                            for chunk in self.chunk_text(response):
                                yield chunk
                            return
                        # N·∫øu kh√¥ng match field c·ª• th·ªÉ, fallback nh∆∞ c≈©
                        question_analysis = self.analyze_specific_question(user_message)
                        import logging
                        logger.debug(f"[UNIVERSITY] intent={intent}, question_analysis={question_analysis}")
                        focused_response = self.generate_focused_response(school_doc, question_analysis, school_name)
                        logger.debug(f"[UNIVERSITY] focused_response={focused_response}")
                        if focused_response and question_analysis["type"] != "general":
                            # C√≥ focused response (v√† user h·ªèi c·ª• th·ªÉ)
                            chat_message = await chat_repository.create_message(
                                session_id, user_message, focused_response, intent
                            )
                            import asyncio
                            await asyncio.sleep(3)
                            for chunk in self.chunk_text(focused_response):
                                yield chunk
                            return
                        else:
                            # Tr·∫£ v·ªÅ markdown chu·∫©n, ch·ªâ field h·ª£p l√Ω
                            markdown_summary = self.format_university_markdown(school_doc)
                            chat_message = await chat_repository.create_message(
                                session_id, user_message, markdown_summary, intent
                            )
                            import asyncio
                            await asyncio.sleep(3)
                            for chunk in self.chunk_text(markdown_summary):
                                yield chunk
                            return
                
                # C√°c intent kh√°c ho·∫∑c kh√¥ng t√¨m ƒë∆∞·ª£c tr∆∞·ªùng ‚Üí d√πng OpenAI
                if intent == "general" and name:
                    user_context = f"""
üë§ USER SHARING PERSONAL INFO:
- User is introducing themselves
- Name: {name}
- Respond warmly, remember their name, and transition to asking how you can help with admissions
"""
                
                # Stream OpenAI
                full_response = ""
                # L∆∞u b·∫£n ghi t·∫°m v√†o DB tr∆∞·ªõc khi stream
                chat_message = await chat_repository.create_message(
                    session_id, user_message, "", intent
                )
                message_id = chat_message["_id"]
                
                import asyncio
                await asyncio.sleep(3)  # Delay 3s cho FE hi·ªÉn th·ªã tr·∫°ng th√°i 'ƒëang suy nghƒ©'
                
                try:
                    async for chunk in openai_service.stream_response(
                        user_message=user_message,
                        intent=intent,
                        context=context,
                        student_data=student_data
                    ):
                        full_response += chunk
                        yield chunk
                    
                    # Update l·∫°i b·∫£n ghi v·ªõi full_response
                    await chat_repository.update_message_bot_response(
                        message_id, full_response
                    )
                    
                except Exception as e:
                    logger.error(f"Error in OpenAI stream: {e}")
                    fallback_response = self._get_enhanced_fallback("error", user_message)
                    await chat_repository.update_message_bot_response(
                        message_id, fallback_response
                    )
                    
                    # ‚úÖ FIX: Chunk fallback response properly
                    for chunk in self.chunk_text(fallback_response):
                        yield chunk
                return
                
        except Exception as e:
            logger.error(f"Error in process_message_stream: {e}")
            fallback_response = self._get_enhanced_fallback("error", user_message)
            
            # L∆∞u fallback v√†o history
            chat_message = await chat_repository.create_message(
                session_id, user_message, fallback_response, "error"
            )
            
            import asyncio
            await asyncio.sleep(3)
            
            # ‚úÖ FIX: Chunk fallback response properly
            for chunk in self.chunk_text(fallback_response):
                yield chunk

    def chunk_text(self, text, chunk_size=32):
        """‚úÖ FIXED: Proper text chunking"""
        for i in range(0, len(text), chunk_size):
            yield text[i:i+chunk_size]

    def normalize_text(self, text):
        # Lo·∫°i b·ªè d·∫•u, chuy·ªÉn v·ªÅ lower, trim
        text = unicodedata.normalize('NFKD', text)
        text = ''.join([c for c in text if not unicodedata.combining(c)])
        return text.lower().strip()

    def extract_university_info_from_question(self, user_message: str) -> str:
        """T√¨m field tr∆∞·ªùng ƒë·∫°i h·ªçc m√† user h·ªèi d·ª±a v√†o keywords/other_name trong knowledge_base.json"""
        kb = knowledge_service.knowledge_base.get("real_school_info", {})
        attrs = kb.get("detailed_attributes", {})
        message_norm = self.normalize_text(user_message)
        for key, meta in attrs.items():
            # L·∫•y keywords v√† other_name n·∫øu c√≥
            keywords = meta.get("keywords", [])
            other_names = meta.get("other_name", [])
            all_keywords = keywords + other_names
            # Chu·∫©n h√≥a keyword ƒë·ªÉ match kh√¥ng d·∫•u, lower
            all_keywords_norm = [self.normalize_text(kw) for kw in all_keywords]
            for kw in all_keywords_norm:
                if kw and kw in message_norm:
                    return key
        return None

    # S·ª≠a l·∫°i field_labels l·∫•y t·ª´ knowledge_base.json
    def get_university_field_labels(self):
        kb = knowledge_service.knowledge_base.get("real_school_info", {})
        attrs = kb.get("detailed_attributes", {})
        field_labels = {}
        for key, meta in attrs.items():
            label = meta.get("description", key)
            field_labels[key] = label
        return field_labels

    def _get_enhanced_fallback(self, intent: str, user_message: str) -> str:
        """Enhanced fallback using knowledge base"""
        try:
            # L·∫•y th√¥ng tin t·ª´ knowledge base cho fallback
            knowledge_context = knowledge_service.search_by_intent(intent)
            
            if knowledge_context:
                description = knowledge_context.get('description', '')
                
                base_message = f"""‚ö†Ô∏è T√¥i ƒëang g·∫∑p s·ª± c·ªë k·ªπ thu·∫≠t t·∫°m th·ªùi v·ªõi **{description}**.

üîß **Nh∆∞ng t√¥i v·∫´n c√≥ th·ªÉ h·ªó tr·ª£ b·∫°n:**"""
                
                # Th√™m g·ª£i √Ω c·ª• th·ªÉ theo intent
                if intent == "score_lookup":
                    base_message += """
- üìä Tra c·ª©u ƒëi·ªÉm thi (cung c·∫•p SBD 8 ch·ªØ s·ªë)
- üìà Ph√¢n t√≠ch ranking v√† x·∫øp h·∫°ng
- üéØ So s√°nh v·ªõi ƒëi·ªÉm chu·∫©n c√°c tr∆∞·ªùng"""

                elif intent == "school_recommendation":
                    base_message += """
- üè´ T∆∞ v·∫•n ch·ªçn tr∆∞·ªùng theo ƒëi·ªÉm s·ªë
- üìç G·ª£i √Ω tr∆∞·ªùng theo khu v·ª±c
- üí∞ Th√¥ng tin h·ªçc ph√≠ v√† ch·∫•t l∆∞·ª£ng"""

                elif intent == "major_advice":
                    base_message += """
- üéì T∆∞ v·∫•n ch·ªçn ng√†nh h·ªçc hot
- üíº Tri·ªÉn v·ªçng ngh·ªÅ nghi·ªáp
- üíµ Th√¥ng tin m·ª©c l∆∞∆°ng theo ng√†nh"""

                base_message += "\n\n‚ùì **B·∫°n c√≥ th·ªÉ th·ª≠ l·∫°i ho·∫∑c ƒë·∫∑t c√¢u h·ªèi c·ª• th·ªÉ h∆°n.**"
                return base_message
            
        except Exception as e:
            print(f"Fallback generation error: {e}")
        
        # Default fallback n·∫øu knowledge base fail
        return """‚ùå Xin l·ªói, t√¥i ƒëang g·∫∑p s·ª± c·ªë k·ªπ thu·∫≠t.

ü§ñ **T√¥i c√≥ th·ªÉ gi√∫p b·∫°n:**
- Tra c·ª©u ƒëi·ªÉm thi (SBD + khu v·ª±c)
- T∆∞ v·∫•n ch·ªçn tr∆∞·ªùng ƒë·∫°i h·ªçc
- Th√¥ng tin ƒëi·ªÉm chu·∫©n v√† ng√†nh h·ªçc
- L·ªãch tuy·ªÉn sinh v√† th·ªß t·ª•c

üîÑ Vui l√≤ng th·ª≠ l·∫°i sau √≠t ph√∫t."""

    async def get_chat_history(self, session_id: str, limit: int = None):
        if limit is None:
            limit = settings.chat_history_limit
        return await chat_repository.get_chat_history(session_id, limit=limit)

    async def get_session_context(self, session_id: str) -> Dict[str, Any]:
        """L·∫•y context chi ti·∫øt c·ªßa session"""
        history = await chat_repository.get_chat_history(session_id, limit=settings.chat_history_limit)
        
        # Ph√¢n t√≠ch patterns trong session
        intents = [msg.get("intent", "general") for msg in history]
        intent_counts = {}
        for intent in intents:
            intent_counts[intent] = intent_counts.get(intent, 0) + 1
        
        # T√¨m entities ƒë√£ ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p
        mentioned_entities = {
            'candidate_numbers': [],
            'schools': [],
            'majors': [],
            'locations': []
        }
        
        for msg in history:
            user_msg = msg.get("user_message", "")
            entities = self.extract_entities(user_msg)
            
            if entities.get('candidate_number'):
                mentioned_entities['candidate_numbers'].append(entities['candidate_number'])
            if entities.get('school_name'):
                mentioned_entities['schools'].append(entities['school_name'])
            if entities.get('major_name'):
                mentioned_entities['majors'].append(entities['major_name'])
            if entities.get('location'):
                mentioned_entities['locations'].append(entities['location'])
        
        # Remove duplicates
        for key in mentioned_entities:
            mentioned_entities[key] = list(set(mentioned_entities[key]))
        
        return {
            "session_id": session_id,
            "message_count": len(history),
            "intent_distribution": intent_counts,
            "most_common_intent": max(intent_counts, key=intent_counts.get) if intent_counts else "general",
            "mentioned_entities": mentioned_entities,
            "recent_intents": intents[-5:] if len(intents) >= 5 else intents,
            "conversation_stage": self._determine_conversation_stage(history)
        }

    def _determine_conversation_stage(self, history: List[Dict[str, Any]]) -> str:
        """X√°c ƒë·ªãnh giai ƒëo·∫°n c·ªßa cu·ªôc tr√≤ chuy·ªán"""
        if len(history) == 0:
            return "new"
        elif len(history) <= 3:
            return "beginning"
        elif len(history) <= 10:
            return "developing"
        else:
            return "extended"

    def format_university_markdown(self, school_doc: Dict[str, Any]) -> str:
        """T·ª± ƒë·ªông xu·∫•t markdown cho th√¥ng tin tr∆∞·ªùng ƒë·∫°i h·ªçc, ch·ªâ l·∫•y c√°c field c√≥ trong schema real_school_info.detailed_attributes"""
        field_labels = self.get_university_field_labels()
        lines = []
        name = school_doc.get("name")
        if name:
            lines.append(f"**{name}**\n")
        # 1. C√°c tr∆∞·ªùng string/number ƒë∆°n gi·∫£n
        for key in ["description", "location", "type", "established", "ranking", "so_sinh_vien", "so_giang_vien", "ty_le_viec_lam", "luong_khoi_diem", "chuong_trinh_quoc_te", "nghien_cuu"]:
            value = school_doc.get(key)
            if value:
                lines.append(f"- **{field_labels.get(key, key)}:** {value}")
        # 2. diem_chuan (object, nhi·ªÅu nƒÉm)
        diem_chuan = school_doc.get("diem_chuan")
        if diem_chuan:
            lines.append(f"\n**{field_labels.get('diem_chuan', 'ƒêi·ªÉm chu·∫©n')}:**")
            for year, year_data in diem_chuan.items():
                lines.append(f"- **NƒÉm {year}:**")
                if isinstance(year_data, dict):
                    if "cao_nhat" in year_data:
                        lines.append(f"  - Cao nh·∫•t: {year_data['cao_nhat']}")
                    if "thap_nhat" in year_data:
                        lines.append(f"  - Th·∫•p nh·∫•t: {year_data['thap_nhat']}")
                    if "nganh_hot" in year_data and isinstance(year_data["nganh_hot"], list):
                        lines.append(f"  - Ng√†nh hot:")
                        for ng in year_data["nganh_hot"]:
                            lines.append(f"    - {ng.get('nganh', '')}: {ng.get('diem', '')}")
        # 3. hoc_phi (object)
        hoc_phi = school_doc.get("hoc_phi")
        if hoc_phi and isinstance(hoc_phi, dict):
            lines.append(f"\n**{field_labels.get('hoc_phi', 'H·ªçc ph√≠')}:**")
            if "khung_gia" in hoc_phi:
                lines.append(f"- Khung gi√°: {hoc_phi['khung_gia']}")
            if "chi_tiet" in hoc_phi:
                lines.append(f"- Chi ti·∫øt: {hoc_phi['chi_tiet']}")
        # 4. hoc_bong (array)
        hoc_bong = school_doc.get("hoc_bong")
        if hoc_bong and isinstance(hoc_bong, list):
            lines.append(f"\n**{field_labels.get('hoc_bong', 'H·ªçc b·ªïng')}:**")
            for hb in hoc_bong:
                lines.append(f"- {hb}")
        # 5. dac_sac (array)
        dac_sac = school_doc.get("dac_sac")
        if dac_sac and isinstance(dac_sac, list):
            lines.append(f"\n**{field_labels.get('dac_sac', 'ƒêi·ªÉm n·ªïi b·∫≠t')}:**")
            for ds in dac_sac:
                lines.append(f"- {ds}")
        return "\n".join(lines)

chat_service = ChatService()